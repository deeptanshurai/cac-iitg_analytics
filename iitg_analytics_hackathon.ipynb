{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWjhOm2WdcsqcB0mvNICiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deeptanshurai/deeptanshu_iitg_analytics/blob/main/iitg_analytics_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBcMHZjj8gkG",
        "outputId": "ac667c47-2ded-43e8-9489-c9f5495bb388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value found: 1\n",
            "\n",
            "Advanced submission file 'download.csv' created successfully!\n",
            "\n",
            "First 5 rows of the advanced submission file:\n",
            "    ID       class\n",
            "0    1      forest\n",
            "1    2      forest\n",
            "2    3      forest\n",
            "3    4      forest\n",
            "4    5      forest\n",
            "5    6      forest\n",
            "6    7      forest\n",
            "7    8      forest\n",
            "8    9      forest\n",
            "9   10        farm\n",
            "10  11      forest\n",
            "11  12      forest\n",
            "12  13      forest\n",
            "13  14      forest\n",
            "14  15      forest\n",
            "15  16      forest\n",
            "16  17      forest\n",
            "17  18      forest\n",
            "18  19      forest\n",
            "19  20      forest\n",
            "20  21      forest\n",
            "21  22      forest\n",
            "22  23      forest\n",
            "23  24       water\n",
            "24  25       water\n",
            "25  26       water\n",
            "26  27  impervious\n",
            "27  28      forest\n",
            "28  29       water\n",
            "29  30       water\n",
            "30  31       water\n",
            "31  32      forest\n",
            "32  33       water\n",
            "33  34      forest\n",
            "34  35  impervious\n",
            "35  36        farm\n",
            "36  37       water\n",
            "37  38       water\n",
            "38  39       water\n",
            "39  40  impervious\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "try:\n",
        "\n",
        "\n",
        "    url_1 = 'https://raw.githubusercontent.com/deeptanshurai/deeptanshu_iitg_analytics/refs/heads/main/hacktrain.csv'\n",
        "    url_2 = 'https://raw.githubusercontent.com/deeptanshurai/deeptanshu_iitg_analytics/refs/heads/main/hacktest.csv'\n",
        "    train_df = pd.read_csv(url_1)\n",
        "    test_df = pd.read_csv(url_2)\n",
        "\n",
        "\n",
        "    # Drop 'Unnamed: 0' column\n",
        "    train_df = train_df.drop('Unnamed: 0', axis=1)\n",
        "    test_df = test_df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "    # Get NDVI\n",
        "    ndvi_cols = [col for col in train_df.columns if '_N' in col]\n",
        "    sorted_ndvi_cols = sorted(ndvi_cols, key=lambda x: pd.to_datetime(x.split('_')[0], format='%Y%m%d'))\n",
        "\n",
        "    train_df = train_df[['ID', 'class'] + sorted_ndvi_cols]\n",
        "    test_df = test_df[['ID'] + sorted_ndvi_cols]\n",
        "\n",
        "    # --- Feature Engineering ---\n",
        "\n",
        "    # 1. Imputation\n",
        "    train_df[sorted_ndvi_cols] = train_df[sorted_ndvi_cols].T.interpolate(method='linear').T\n",
        "    # edge cases\n",
        "    train_df[sorted_ndvi_cols] = train_df[sorted_ndvi_cols].bfill(axis=1).ffill(axis=1)\n",
        "\n",
        "    # 2.Savitzky-Golay filter\n",
        "\n",
        "    window_length = 5\n",
        "    polyorder = 2\n",
        "    train_df[sorted_ndvi_cols] = savgol_filter(train_df[sorted_ndvi_cols], window_length, polyorder, axis=1)\n",
        "    test_df[sorted_ndvi_cols] = savgol_filter(test_df[sorted_ndvi_cols], window_length, polyorder, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_advanced_features(df):\n",
        "        features = pd.DataFrame()\n",
        "\n",
        "\n",
        "        features['mean_ndvi'] = df[sorted_ndvi_cols].mean(axis=1)\n",
        "        features['median_ndvi'] = df[sorted_ndvi_cols].median(axis=1)\n",
        "        features['std_ndvi'] = df[sorted_ndvi_cols].std(axis=1)\n",
        "        features['max_ndvi'] = df[sorted_ndvi_cols].max(axis=1)\n",
        "        features['min_ndvi'] = df[sorted_ndvi_cols].min(axis=1)\n",
        "        features['range_ndvi'] = features['max_ndvi'] - features['min_ndvi']\n",
        "\n",
        "\n",
        "        months = [int(col.split('_')[0][4:6]) for col in sorted_ndvi_cols]\n",
        "        winter_cols = [col for col, m in zip(sorted_ndvi_cols, months) if m in [12, 1, 2]]\n",
        "        spring_cols = [col for col, m in zip(sorted_ndvi_cols, months) if m in [3, 4, 5]]\n",
        "        summer_cols = [col for col, m in zip(sorted_ndvi_cols, months) if m in [6, 7, 8]]\n",
        "        autumn_cols = [col for col, m in zip(sorted_ndvi_cols, months) if m in [9, 10, 11]]\n",
        "\n",
        "        features['winter_mean_ndvi'] = df[winter_cols].mean(axis=1)\n",
        "        features['spring_mean_ndvi'] = df[spring_cols].mean(axis=1)\n",
        "        features['summer_mean_ndvi'] = df[summer_cols].mean(axis=1)\n",
        "        features['autumn_mean_ndvi'] = df[autumn_cols].mean(axis=1)\n",
        "\n",
        "\n",
        "        fft_features = np.fft.fft(df[sorted_ndvi_cols], axis=1)\n",
        "\n",
        "        fft_magnitudes = np.abs(fft_features)\n",
        "\n",
        "\n",
        "        for i in range(1, 6):\n",
        "            features[f'fft_mag_{i}'] = fft_magnitudes[:, i]\n",
        "\n",
        "        return features\n",
        "\n",
        "    X_train_features = get_advanced_features(train_df)\n",
        "    X_test_features = get_advanced_features(test_df)\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_features)\n",
        "    X_test_scaled = scaler.transform(X_test_features)\n",
        "\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(train_df['class'])\n",
        "\n",
        "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "    # Initialize the Logistic Regression model\n",
        "    log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=3000, random_state=42)\n",
        "\n",
        "    # Initialize GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(f\"Best C value found: {grid_search.best_params_['C']}\")\n",
        "\n",
        "\n",
        "    best_log_reg = grid_search.best_estimator_\n",
        "\n",
        "    # Prediction\n",
        "    test_predictions = best_log_reg.predict(X_test_scaled)\n",
        "    test_predictions_labels = le.inverse_transform(test_predictions)\n",
        "\n",
        "\n",
        "    submission_df = pd.DataFrame({'ID': test_df['ID'], 'class': test_predictions_labels})\n",
        "    submission_df.to_csv('download.csv', index=False)\n",
        "\n",
        "    print(\"\\nAdvanced submission file 'download.csv' created successfully!\")\n",
        "    print(\"\\nFirst 5 rows of the advanced submission file:\")\n",
        "    print(submission_df.head(40))\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ]
}